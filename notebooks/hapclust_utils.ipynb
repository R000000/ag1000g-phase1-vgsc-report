{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".container {\n",
       "    width: 100%;\n",
       "}\n",
       "div#notebook {\n",
       "    padding-top: 0;\n",
       "}\n",
       "#header-container {\n",
       "    display: none;\n",
       "}\n",
       "#header-bar {\n",
       "    display: none;\n",
       "}\n",
       "#maintoolbar {\n",
       "    display: none;\n",
       "}\n",
       "#site {\n",
       "    height: auto !important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to support searching a scipy tree.\n",
    "\n",
    "def get_descendant(node, desc_id):\n",
    "    \"\"\"Search the descendants of the given node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node : scipy.cluster.hierarchy.ClusterNode\n",
    "        The ancestor node to search from.\n",
    "    desc_id : int\n",
    "        The ID of the node to search for.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    desc : scipy.cluster.hierarchy.ClusterNode\n",
    "        If a node with the given ID is not found, returns None.\n",
    "    \n",
    "    \"\"\"\n",
    "    if node.id == desc_id:\n",
    "        return node\n",
    "    if node.is_leaf():\n",
    "        return None\n",
    "    if node.left.id == desc_id:\n",
    "        return node.left\n",
    "    if node.right.id == desc_id:\n",
    "        return node.right\n",
    "    # search left\n",
    "    l = get_descendant(node.left, desc_id)\n",
    "    if l is not None:\n",
    "        return l\n",
    "    # search right\n",
    "    r = get_descendant(node.right, desc_id)\n",
    "    return r\n",
    "\n",
    "\n",
    "# monkey-patch as a method\n",
    "scipy.cluster.hierarchy.ClusterNode.get_descendant = get_descendant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fig_haplotypes_clustered(h,\n",
    "                             distance_metric='hamming',\n",
    "                             linkage_method='single',\n",
    "                             truncate_distance=0,\n",
    "                             orientation='top',\n",
    "                             subplot_ratios=(4, 2),\n",
    "                             subplot_pad=0,\n",
    "                             despine_offset=5,\n",
    "                             count_sort=True,\n",
    "                             dend_linecolor='k',\n",
    "                             cut_height=2,\n",
    "                             highlight_clusters=True,\n",
    "                             highlight_colors=None,\n",
    "                             highlight_dend=True,\n",
    "                             highlight_freq=True,\n",
    "                             highlight_alpha=0.3,\n",
    "                             label_clusters=True,\n",
    "                             dpi=None,\n",
    "                             fig=None,\n",
    "                             ):\n",
    "    \"\"\"Construct a plot of hierarchical clustering of haplotypes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    TODO\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    TODO\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # check inputs\n",
    "    h = allel.HaplotypeArray(h)\n",
    "    \n",
    "    # compute distance matrix\n",
    "    dist = scipy.spatial.distance.pdist(h.T, metric=distance_metric)\n",
    "    if distance_metric in {'hamming', 'jaccard'}:\n",
    "        # convert distance to number of SNPs, easier to interpret\n",
    "        dist *= h.n_variants\n",
    "    \n",
    "    # compute hierarchical clustering\n",
    "    Z = scipy.cluster.hierarchy.linkage(dist, method=linkage_method)\n",
    "\n",
    "    # Z is a linkage matrix. From the scipy docs...\n",
    "    # A 4 by (n-1) matrix Z is returned. At the i-th iteration, clusters with \n",
    "    # indices Z[i, 0] and Z[i, 1] are combined to form cluster n + i. A cluster \n",
    "    # with an index less than n corresponds to one of the original observations. \n",
    "    # The distance between clusters Z[i, 0] and Z[i, 1] is given by Z[i, 2]. The \n",
    "    # fourth value Z[i, 3] represents the number of original observations in the \n",
    "    # newly formed cluster.\n",
    "    \n",
    "    # find level to truncate dendrogram\n",
    "    lastp = h.n_haplotypes - bisect.bisect_right(Z[:, 2], truncate_distance)\n",
    "    \n",
    "    # convenience variables\n",
    "    horizontal = orientation in ['left', 'right']\n",
    "    vertical = not horizontal\n",
    "    inverted = orientation in ['bottom', 'right']\n",
    "    \n",
    "    # setup figure\n",
    "    if fig is None:\n",
    "        figsize = plt.rcParams['figure.figsize']\n",
    "        if horizontal:\n",
    "            figsize = figsize[::-1]\n",
    "        fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "        \n",
    "    # setup gridspec and axes\n",
    "    if inverted:\n",
    "        subplot_ratios = subplot_ratios[::-1]\n",
    "    if horizontal:\n",
    "        gs = plt.GridSpec(nrows=1, ncols=2, width_ratios=subplot_ratios)\n",
    "    else:\n",
    "        gs = plt.GridSpec(nrows=2, ncols=1, height_ratios=subplot_ratios)\n",
    "    if inverted:\n",
    "        ax_dend = fig.add_subplot(gs[1])\n",
    "        ax_freq = fig.add_subplot(gs[0])\n",
    "    else:\n",
    "        ax_dend = fig.add_subplot(gs[0])\n",
    "        ax_freq = fig.add_subplot(gs[1])\n",
    "    if horizontal:\n",
    "        sns.despine(ax=ax_dend, offset=despine_offset, \n",
    "                    left=True, top=True, right=True, bottom=False)\n",
    "        sns.despine(ax=ax_freq, offset=despine_offset, \n",
    "                    left=True, top=True, right=True, bottom=False)\n",
    "    else:\n",
    "        sns.despine(ax=ax_dend, offset=despine_offset, \n",
    "                    left=False, top=True, right=True, bottom=True)\n",
    "        sns.despine(ax=ax_freq, offset=despine_offset, \n",
    "                    left=False, top=True, right=True, bottom=True)\n",
    "\n",
    "    # make a dendrogram\n",
    "    kwargs_dend = dict(\n",
    "        truncate_mode='lastp', \n",
    "        p=lastp,\n",
    "        show_leaf_counts=False, \n",
    "        count_sort=count_sort, \n",
    "        no_labels=True, \n",
    "        color_threshold=0, \n",
    "        above_threshold_color=dend_linecolor, \n",
    "        orientation=orientation\n",
    "    )    \n",
    "    dend = scipy.cluster.hierarchy.dendrogram(Z, ax=ax_dend, **kwargs_dend)\n",
    "    leaves = dend['leaves']\n",
    "    ax_dend_label = 'Distance'\n",
    "    if horizontal:\n",
    "        ax_dend.set_xlabel(ax_dend_label)\n",
    "        ax_dend.set_yticks([])\n",
    "    else:\n",
    "        ax_dend.set_ylabel(ax_dend_label)\n",
    "        ax_dend.set_xticks([])\n",
    "        \n",
    "    # construct a tree and compute observation counts for the dendrogram leaves\n",
    "    tree = scipy.cluster.hierarchy.to_tree(Z)\n",
    "    s = np.arange(len(leaves))\n",
    "    t = np.array([\n",
    "        1 if l < h.n_haplotypes\n",
    "        else tree.get_descendant(l).get_count()\n",
    "        for l in leaves\n",
    "    ])\n",
    "\n",
    "    # plot frequencies bar\n",
    "    ax_freq_label = 'Frequency'\n",
    "    if horizontal:\n",
    "        ax_freq.barh(s, t, height=1, lw=0, color='k', align='edge')\n",
    "        ax_freq.set_ylim(0, len(leaves))\n",
    "        ax_freq.set_yticks([])\n",
    "        ax_freq.set_xlabel(ax_freq_label)\n",
    "        ax_freq.grid(axis='x', lw=.5)\n",
    "        if orientation == 'right':\n",
    "            ax_freq.invert_xaxis()\n",
    "        # remove 0\n",
    "        ax_freq.set_xticks(ax_freq.get_xticks()[1:])\n",
    "    else:\n",
    "        ax_freq.bar(s, t, width=1, lw=0, color='k', align='edge')\n",
    "        ax_freq.set_xlim(0, len(leaves))\n",
    "        ax_freq.set_xticks([])\n",
    "        ax_freq.set_ylabel(ax_freq_label)\n",
    "        ax_freq.grid(axis='y', lw=.5)\n",
    "        if orientation == 'top':\n",
    "            ax_freq.invert_yaxis()\n",
    "        # remove 0\n",
    "        ax_freq.set_yticks(ax_freq.get_yticks()[1:])\n",
    "\n",
    "    # cut the tree\n",
    "    cut = scipy.cluster.hierarchy.cut_tree(Z, height=cut_height)[:, 0]\n",
    "    cluster_sizes = np.bincount(cut)\n",
    "    clusters = [np.nonzero(cut == i)[0] for i in range(cut.max() + 1)]\n",
    "    \n",
    "    # now the fiddly bit - we need to figure out where the clusters have\n",
    "    # ended up in the dendrogram we plotted earlier...\n",
    "    \n",
    "    # N.B., the dendrogram was truncated, so each leaf in the dendrogram\n",
    "    # may correspond to more than one original observation (i.e., haplotype).\n",
    "    # Let's build a list storing the observations for each leaf:\n",
    "    leaf_obs = [tree.get_descendant(ix).pre_order() for ix in leaves]\n",
    "    \n",
    "    # Now let's figure out for each leaf in the dendrogram, which of the clusters\n",
    "    # obtained by cutting the tree earlier does it fall into?\n",
    "    leaf_clusters = np.array([cut[l[0]] for l in leaf_obs])\n",
    "    \n",
    "    # Now let's build a data structure that reorders the clusters so they\n",
    "    # occur in the same order as in the dendrogram, and also record the indices\n",
    "    # of the start and stop leaf for each cluster:\n",
    "    cluster_spans = list()\n",
    "    c_prv = leaf_clusters[0]\n",
    "    i_start = 0\n",
    "    for i, c in enumerate(leaf_clusters[1:], 1):\n",
    "        if c != c_prv:\n",
    "            cluster_spans.append((i_start, i, clusters[c_prv]))\n",
    "            i_start = i\n",
    "        c_prv = c\n",
    "    # don't forget the last one\n",
    "    cluster_spans.append((i_start, i+1, clusters[c]))\n",
    "    \n",
    "    # OK, now figure out which clusters we want to highlight...\n",
    "    if isinstance(highlight_clusters, (list, tuple)):\n",
    "        # user has manually specified which clusters to highlight\n",
    "        pass\n",
    "    else:\n",
    "        # assume highlight_clusters is the minimum cluster size to highlight\n",
    "        min_cluster_size = int(highlight_clusters)\n",
    "        highlight_clusters = [i for i, cs in enumerate(cluster_spans) \n",
    "                              if len(cs[2]) >= min_cluster_size]\n",
    "        \n",
    "    # setup colors for highlighting clusters\n",
    "    if highlight_colors is None:\n",
    "        highlight_colors = sns.color_palette('hls', n_colors=len(highlight_clusters))\n",
    "        \n",
    "    # do the highlighting\n",
    "    for color, cix in zip(highlight_colors, highlight_clusters):\n",
    "        start, stop, _ = cluster_spans[cix]\n",
    "        if horizontal:\n",
    "            freq_spanf = ax_freq.axhspan\n",
    "            dend_patch_xy = (0, start * 10)\n",
    "            dend_patch_width = cut_height\n",
    "            dend_patch_height = (stop - start) * 10\n",
    "        else:\n",
    "            freq_spanf = ax_freq.axvspan\n",
    "            dend_patch_xy = (start * 10, 0)\n",
    "            dend_patch_width = (stop - start) * 10\n",
    "            dend_patch_height = cut_height\n",
    "        if highlight_freq:\n",
    "            freq_spanf(start, stop, color=color, alpha=highlight_alpha, zorder=-20)\n",
    "        if highlight_dend:\n",
    "            ax_dend.add_patch(plt.Rectangle(xy=dend_patch_xy, \n",
    "                                            width=dend_patch_width, \n",
    "                                            height=dend_patch_height, \n",
    "                                            color=color, alpha=highlight_alpha, \n",
    "                                            zorder=-20))\n",
    "\n",
    "    # for debugging, label the clusters\n",
    "    if label_clusters:\n",
    "        for i, (start, stop, clst) in enumerate(cluster_spans):\n",
    "            if horizontal:\n",
    "                x = max(ax_freq.get_xlim())\n",
    "                y = (start + stop) / 2\n",
    "                ha = orientation\n",
    "                va = 'center'\n",
    "            else:\n",
    "                x = (start + stop) / 2\n",
    "                y = max(ax_freq.get_ylim())\n",
    "                ha = 'center'\n",
    "                va = orientation\n",
    "            # treat label_clusters as minimum cluster size to label\n",
    "            if len(clst) >= int(label_clusters):\n",
    "                ax_freq.text(x, y, str(i), \n",
    "                             va=va, ha=ha, fontsize=6)\n",
    "    \n",
    "    # tidy up plot\n",
    "    if horizontal:\n",
    "        gs.tight_layout(fig, w_pad=subplot_pad)\n",
    "    else:\n",
    "        gs.tight_layout(fig, h_pad=subplot_pad)\n",
    "    \n",
    "    # return some useful stuff\n",
    "    return fig, ax_dend, ax_freq, cluster_spans, leaf_obs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haplotype networks (via minimum spanning tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _graph_edges(graph, \n",
    "                 edges, \n",
    "                 hap_counts, \n",
    "                 node_size_factor, \n",
    "                 edge_length,\n",
    "                 anon_width,\n",
    "                 intermediate_nodes,\n",
    "                 edge_attrs,\n",
    "                 anon_node_attrs):\n",
    "    \n",
    "    for i in range(edges.shape[0]):\n",
    "\n",
    "        for j in range(edges.shape[1]):\n",
    "\n",
    "            # lookup distance between nodes i and j\n",
    "            sep = edges[i, j]\n",
    "\n",
    "            if sep > 0:\n",
    "\n",
    "                # lookup number of haplotypes\n",
    "                n_i = hap_counts[i]\n",
    "                n_j = hap_counts[j]\n",
    "\n",
    "                # calculate node sizes (needed to adjust edge length)\n",
    "                width_i = np.sqrt(n_i * node_size_factor)\n",
    "                width_j = np.sqrt(n_j * node_size_factor)\n",
    "\n",
    "                if sep > 1 and intermediate_nodes:\n",
    "\n",
    "                    # tricky case, need to add some anonymous nodes to represent intermediate steps\n",
    "\n",
    "                    # add first intermediate node\n",
    "                    nid = 'anon_{}_{}_{}'.format(i, j, 0)\n",
    "                    graph.node(nid, label='', width=str(anon_width), **anon_node_attrs)\n",
    "\n",
    "                    # add edge from node i to first intermediate\n",
    "                    el = edge_length + width_i / 2 + anon_width / 2\n",
    "                    kwargs = {'len': str(el)}\n",
    "                    kwargs.update(edge_attrs)\n",
    "                    graph.edge(str(i), 'anon_{}_{}_{}'.format(i, j, 0), **kwargs)\n",
    "\n",
    "                    # add further intermediate nodes as necessary\n",
    "                    for k in range(1, sep-1):\n",
    "                        nid = 'anon_{}_{}_{}'.format(i, j, k)\n",
    "                        graph.node(nid, label='', width=str(anon_width), **anon_node_attrs)\n",
    "                        el = edge_length + anon_width\n",
    "                        kwargs = {'len': str(el)}\n",
    "                        kwargs.update(edge_attrs)\n",
    "                        graph.edge('anon_{}_{}_{}'.format(i, j, k-1), 'anon_{}_{}_{}'.format(i, j, k), **kwargs)\n",
    "\n",
    "                    # add edge from final intermediate node to node j\n",
    "                    el = edge_length + anon_width / 2 + width_j / 2 \n",
    "                    kwargs = {'len': str(el)}\n",
    "                    kwargs.update(edge_attrs)\n",
    "                    graph.edge('anon_{}_{}_{}'.format(i, j, sep-2), str(j), **kwargs)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # simple case, direct edge from node i to j\n",
    "\n",
    "                    # N.B., adjust edge length so we measure distance from edge of circle rather than center\n",
    "                    el = (edge_length * sep) + width_i / 2 + width_j / 2\n",
    "                    kwargs = {'len': str(el)}\n",
    "                    kwargs.update(edge_attrs)\n",
    "                    graph.edge(str(i), str(j), **kwargs)\n",
    "\n",
    "                    \n",
    "def graph_haplotype_network(h,\n",
    "                            hap_colors='grey',\n",
    "                            distance_metric='hamming',\n",
    "                            network_method='mst',\n",
    "                            comment=None,\n",
    "                            engine='neato',\n",
    "                            format='png',\n",
    "                            mode='major',\n",
    "                            overlap=True,\n",
    "                            splines=False,\n",
    "                            node_size_factor=0.01,\n",
    "                            node_attrs=None,\n",
    "                            show_node_labels=False,\n",
    "                            edge_length=0.5,\n",
    "                            edge_weight=10,\n",
    "                            edge_attrs=None,\n",
    "                            show_alternate_edges=True,\n",
    "                            alternate_edge_attrs=None,\n",
    "                            anon_width=0.07,\n",
    "                            anon_fillcolor='white',\n",
    "                            anon_node_attrs=None,\n",
    "                            intermediate_nodes=True,\n",
    "                            max_dist=5,\n",
    "                            debug=False,\n",
    "                            ):\n",
    "    \"\"\"TODO doc me\"\"\"\n",
    "    \n",
    "    # check inputs\n",
    "    h = allel.HaplotypeArray(h)\n",
    "    \n",
    "    # find distinct haplotypes\n",
    "    h_distinct_sets = h.distinct()\n",
    "    \n",
    "    # find indices of distinct haplotypes - just need one per set\n",
    "    h_distinct_indices = sorted([sorted(s)[0] for s in h_distinct_sets])\n",
    "    \n",
    "    # obtain an array of distinct haplotypes\n",
    "    h_distinct = h.take(h_distinct_indices, axis=1)\n",
    "\n",
    "    # deal with colors - count how many of each color per distinct haplotype\n",
    "    color_counters = None\n",
    "    if isinstance(hap_colors, (list, tuple, np.ndarray)):\n",
    "        assert len(hap_colors) == h.n_haplotypes\n",
    "        color_counters = [\n",
    "            collections.Counter([hap_colors[i] for i in s])\n",
    "            for s in h_distinct_sets\n",
    "        ]\n",
    "\n",
    "    # count how many observations per distinct haplotype\n",
    "    hap_counts = [len(s) for s in h_distinct_sets]\n",
    "\n",
    "    # compute pairwise distance matrix\n",
    "    assert distance_metric in ['hamming', 'jaccard']\n",
    "    dist = allel.pairwise_distance(h_distinct, metric=distance_metric)\n",
    "    dist *= h.n_variants\n",
    "    dist = scipy.spatial.distance.squareform(dist).astype(int)\n",
    "\n",
    "    if network_method.lower() == 'mst':\n",
    "\n",
    "        # compute minimum spanning tree\n",
    "        edges = scipy.sparse.csgraph.minimum_spanning_tree(dist).toarray().astype(int)\n",
    "\n",
    "        # deal with maximum distance\n",
    "        if max_dist:\n",
    "            edges[edges > max_dist] = 0\n",
    "\n",
    "        # no alternate edges when using mst\n",
    "        alternate_edges = None\n",
    "        \n",
    "    elif network_method.lower() == 'msn':\n",
    "        \n",
    "        # compute network\n",
    "        edges, alternate_edges = minimum_spanning_network(dist, max_dist=max_dist, debug=debug)\n",
    "\n",
    "    # setup graph\n",
    "    graph = graphviz.Graph(comment=comment, engine=engine, format=format)\n",
    "    graph.attr('graph', overlap=str(overlap).lower(), splines=str(splines).lower(), mode=mode)\n",
    "\n",
    "    # add the main nodes\n",
    "    if node_attrs is None:\n",
    "        node_attrs = dict()\n",
    "    node_attrs.setdefault('fixedsize', 'true')\n",
    "    node_attrs.setdefault('shape', 'circle')\n",
    "    for i, n in enumerate(hap_counts):\n",
    "        # TODO iterate over shape of edges, make any extra (median) nodes appear like intermediates\n",
    "\n",
    "        # calculate width from number of items - make width proportional to area\n",
    "        width = np.sqrt(n * node_size_factor)\n",
    "\n",
    "        # determine style and fill color\n",
    "        if color_counters:\n",
    "            cc = color_counters[i]\n",
    "            if len(cc) > 1:\n",
    "                # more than one color, make a pie chart\n",
    "                style = 'wedged'\n",
    "                fillcolor = ':'.join(['%s;%s' % (k, v/n) for k, v in cc.items()])\n",
    "            else:\n",
    "                # just one color, fill with solid color\n",
    "                style = 'filled'\n",
    "                fillcolor = list(cc.keys())[0]\n",
    "        else:\n",
    "            style = 'filled'\n",
    "            fillcolor = hap_colors\n",
    "\n",
    "        # add graph node\n",
    "        if show_node_labels:\n",
    "            label = str(i)\n",
    "        else:\n",
    "            label = \"\"\n",
    "        kwargs = dict()\n",
    "        kwargs.update(node_attrs)\n",
    "        kwargs.setdefault('style', style)\n",
    "        kwargs.setdefault('fillcolor', fillcolor)\n",
    "        kwargs.setdefault('label', label)\n",
    "        kwargs.setdefault('width', str(width))\n",
    "        graph.node(str(i), **kwargs)\n",
    "    \n",
    "    # setup defaults\n",
    "    if anon_node_attrs is None:\n",
    "        anon_node_attrs = dict()\n",
    "    anon_node_attrs.setdefault('fixedsize', 'true')\n",
    "    anon_node_attrs.setdefault('shape', 'circle')\n",
    "    anon_node_attrs.setdefault('style', 'filled')\n",
    "    anon_node_attrs.setdefault('fillcolor', anon_fillcolor)\n",
    "    if edge_attrs is None:\n",
    "        edge_attrs = dict()\n",
    "    edge_attrs.setdefault('style', 'normal')\n",
    "    edge_attrs.setdefault('weight', str(edge_weight))\n",
    "    if alternate_edge_attrs is None:\n",
    "        alternate_edge_attrs = dict()\n",
    "    alternate_edge_attrs.setdefault('style', 'dashed')\n",
    "    alternate_edge_attrs.setdefault('weight', str(edge_weight))\n",
    "\n",
    "    # add main edges\n",
    "    _graph_edges(graph, \n",
    "                 edges, \n",
    "                 hap_counts, \n",
    "                 node_size_factor, \n",
    "                 edge_length,\n",
    "                 anon_width,\n",
    "                 intermediate_nodes,\n",
    "                 edge_attrs,\n",
    "                 anon_node_attrs)\n",
    "    \n",
    "    # add alternate edges\n",
    "    if show_alternate_edges and alternate_edges is not None:\n",
    "        _graph_edges(graph, \n",
    "                     alternate_edges, \n",
    "                     hap_counts, \n",
    "                     node_size_factor, \n",
    "                     edge_length,\n",
    "                     anon_width,\n",
    "                     intermediate_nodes,\n",
    "                     alternate_edge_attrs,\n",
    "                     anon_node_attrs)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimum_spanning_network(dist, max_dist=None, debug=False):\n",
    "    \"\"\"TODO\"\"\"\n",
    "    \n",
    "    # TODO review implementation, see if this can be tidied up\n",
    "    \n",
    "    # keep only the lower triangle of the distance matrix, to avoid adding the same\n",
    "    # edge twice\n",
    "    dist = np.triu(dist)\n",
    "    \n",
    "    # setup the output array of links between nodes\n",
    "    edges = np.zeros_like(dist)\n",
    "    \n",
    "    # setup an array of alternate links\n",
    "    alternate_edges = np.zeros_like(dist)\n",
    "    \n",
    "    # intermediate variable - assignment of haplotypes to clusters (a.k.a. sub-networks)\n",
    "    # initially each distinct haplotype is in its own cluster\n",
    "    cluster = np.arange(dist.shape[0])\n",
    "    \n",
    "    # start with haplotypes separated by a single mutation\n",
    "    step = 1\n",
    "    \n",
    "    # iterate until all haplotypes in a single cluster, or max_dist reached\n",
    "    while len(set(cluster)) > 1 and (max_dist is None or step <= max_dist):\n",
    "        if debug: print('processing step', step, cluster)\n",
    "            \n",
    "        # keep track of which clusters have been merged at this height\n",
    "        merged = set()\n",
    "        \n",
    "        # remember what cluster assignments were at the previous height\n",
    "        prv_cluster = cluster.copy()\n",
    "        \n",
    "        # iterate over all pairs where distance equals current step size\n",
    "        for i, j in zip(*np.nonzero(dist == step)):\n",
    "            if debug: print('found potential edge', i, j)\n",
    "            \n",
    "            # current cluster assignment for each haplotype\n",
    "            a = cluster[i]\n",
    "            b = cluster[j]\n",
    "            \n",
    "            # previous cluster assignment for each haplotype\n",
    "            pa = prv_cluster[i]\n",
    "            pb = prv_cluster[j]\n",
    "            \n",
    "            if debug: print(a, b, pa, pb, merged)\n",
    "            \n",
    "            # check to see if both nodes already in the same cluster\n",
    "            if a != b:\n",
    "                \n",
    "                # nodes are in different clusters, so we can merge (i.e., connect) the clusters\n",
    "                \n",
    "                if debug: print('assign an edge')\n",
    "                edges[i, j] = dist[i, j]\n",
    "                \n",
    "                # merge clusters\n",
    "                c = cluster.max() + 1\n",
    "                loc_a = cluster == a\n",
    "                loc_b = cluster == b\n",
    "                cluster[loc_a] = c\n",
    "                cluster[loc_b] = c\n",
    "                merged.add(tuple(sorted([pa, pb])))\n",
    "                if debug: print('merged', cluster, merged)\n",
    "\n",
    "            elif tuple(sorted([pa, pb])) in merged or step == 1:\n",
    "                \n",
    "                # the two clusters have already been merged at this level, this is an alternate connection\n",
    "                # N.B., special case step = 1 because no previous cluster assignments\n",
    "                \n",
    "                if debug: print('assign an alternate edge')\n",
    "                alternate_edges[i, j] = dist[i, j]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if debug: print('')\n",
    "                    \n",
    "        # increment step\n",
    "        step += 1\n",
    "                \n",
    "    return edges, alternate_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = allel.HaplotypeArray([[0, 1, 1, 0],\n",
    "                          [0, 1, 0, 1],\n",
    "                          [0, 0, 1, 1],\n",
    "                          [0, 0, 1, 0],\n",
    "                          [0, 0, 0, 1]])\n",
    "h = h[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 3],\n",
       "       [2, 0, 3, 3],\n",
       "       [3, 3, 0, 4],\n",
       "       [3, 3, 4, 0]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = allel.pairwise_distance(h, metric='hamming')\n",
    "dist *= h.n_variants\n",
    "dist = scipy.spatial.distance.squareform(dist).astype(int)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"182pt\" height=\"292pt\"\n",
       " viewBox=\"0.00 0.00 182.16 292.02\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(91.143 146.053)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-91.143,145.965 -91.143,-146.053 91.0219,-146.053 91.0219,145.965 -91.143,145.965\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"-62.1876\" cy=\"-5.49395\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"-62.1876\" y=\"-1.79395\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- anon_0_1_0 -->\n",
       "<g id=\"node5\" class=\"node\"><title>anon_0_1_0</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"0.375315\" cy=\"0.157867\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;anon_0_1_0 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&#45;anon_0_1_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-46.0761,-4.03847C-31.0148,-2.67786 -9.76294,-0.758003 -2.32297,-0.085891\"/>\n",
       "</g>\n",
       "<!-- anon_0_2_0 -->\n",
       "<g id=\"node6\" class=\"node\"><title>anon_0_2_0</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"-84.643\" cy=\"53.574\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;anon_0_2_0 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>0&#45;&#45;anon_0_2_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-67.9704,9.71752C-73.3763,23.9374 -81.0041,44.0021 -83.6745,51.0265\"/>\n",
       "</g>\n",
       "<!-- anon_0_3_0 -->\n",
       "<g id=\"node8\" class=\"node\"><title>anon_0_3_0</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"-73.6127\" cy=\"-67.5966\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;anon_0_3_0 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>0&#45;&#45;anon_0_3_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-65.1299,-21.4869C-67.8803,-36.4374 -71.7613,-57.5329 -73.1199,-64.9182\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"62.9207\" cy=\"5.59293\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.9207\" y=\"9.29293\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- anon_1_2_0 -->\n",
       "<g id=\"node10\" class=\"node\"><title>anon_1_2_0</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"73.8757\" cy=\"67.9072\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;anon_1_2_0 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>1&#45;&#45;anon_1_2_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M65.7419,21.6404C68.3792,36.6418 72.1005,57.8092 73.4032,65.2196\"/>\n",
       "</g>\n",
       "<!-- anon_1_3_0 -->\n",
       "<g id=\"node12\" class=\"node\"><title>anon_1_3_0</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"84.5219\" cy=\"-53.8364\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;anon_1_3_0 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>1&#45;&#45;anon_1_3_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M68.4836,-9.71161C73.6838,-24.0185 81.0215,-44.206 83.5903,-51.2733\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"-11.4147\" cy=\"125.965\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"-11.4147\" y=\"129.665\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"10.9822\" cy=\"-126.053\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"10.9822\" y=\"-122.353\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n",
       "</g>\n",
       "<!-- anon_0_1_0&#45;&#45;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>anon_0_1_0&#45;&#45;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3.06281,0.391405C10.4983,1.03753 31.7882,2.88758 46.8544,4.1968\"/>\n",
       "</g>\n",
       "<!-- anon_0_2_1 -->\n",
       "<g id=\"node7\" class=\"node\"><title>anon_0_2_1</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"-68.8614\" cy=\"96.7931\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- anon_0_2_0&#45;&#45;anon_0_2_1 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>anon_0_2_0&#45;&#45;anon_0_2_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-83.703,56.1482C-80.8895,63.8533 -72.5576,86.6707 -69.7767,94.2866\"/>\n",
       "</g>\n",
       "<!-- anon_0_2_1&#45;&#45;2 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>anon_0_2_1&#45;&#45;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-66.393,98.0466C-59.5207,101.536 -39.7629,111.569 -25.9109,118.603\"/>\n",
       "</g>\n",
       "<!-- anon_0_3_1 -->\n",
       "<g id=\"node9\" class=\"node\"><title>anon_0_3_1</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"-50.7386\" cy=\"-107.485\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- anon_0_3_0&#45;&#45;anon_0_3_1 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>anon_0_3_0&#45;&#45;anon_0_3_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-72.1118,-70.2138C-67.8976,-77.5626 -56.0056,-98.3002 -52.0423,-105.212\"/>\n",
       "</g>\n",
       "<!-- anon_0_3_1&#45;&#45;3 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>anon_0_3_1&#45;&#45;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-48.0866,-108.283C-40.703,-110.504 -19.4751,-116.89 -4.59253,-121.367\"/>\n",
       "</g>\n",
       "<!-- anon_1_2_1 -->\n",
       "<g id=\"node11\" class=\"node\"><title>anon_1_2_1</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"50.2948\" cy=\"107.451\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- anon_1_2_0&#45;&#45;anon_1_2_1 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>anon_1_2_0&#45;&#45;anon_1_2_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M72.3285,70.5018C67.984,77.7872 55.7246,98.3457 51.6387,105.197\"/>\n",
       "</g>\n",
       "<!-- anon_1_2_1&#45;&#45;2 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>anon_1_2_1&#45;&#45;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M47.6432,108.247C40.261,110.461 19.0371,116.829 4.15723,121.293\"/>\n",
       "</g>\n",
       "<!-- anon_1_3_1 -->\n",
       "<g id=\"node13\" class=\"node\"><title>anon_1_3_1</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"68.4873\" cy=\"-96.9763\" rx=\"2.5\" ry=\"2.5\"/>\n",
       "</g>\n",
       "<!-- anon_1_3_0&#45;&#45;anon_1_3_1 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>anon_1_3_0&#45;&#45;anon_1_3_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M83.5669,-56.4058C80.7082,-64.0968 72.2428,-86.8724 69.4172,-94.4744\"/>\n",
       "</g>\n",
       "<!-- anon_1_3_1&#45;&#45;3 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>anon_1_3_1&#45;&#45;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M66.0163,-98.2256C59.1371,-101.704 39.3592,-111.704 25.4932,-118.716\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x7fbfab467ba8>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_haplotype_network(h, network_method='msn', show_node_labels=True, node_size_factor=0.2, debug=False, max_dist=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_haps = h.n_haplotypes\n",
    "n_haps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_aug = allel.HaplotypeArray(h.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"230pt\" height=\"289pt\"\n",
       " viewBox=\"0.00 0.00 230.21 288.53\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(127.261 121.059)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-127.261,167.473 -127.261,-121.059 102.953,-121.059 102.953,167.473 -127.261,167.473\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"30.8037\" cy=\"-13.6322\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"30.8037\" y=\"-9.93216\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"77.2629\" cy=\"45.5575\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"77.2629\" y=\"49.2575\" font-family=\"Times,serif\" font-size=\"14.00\">4</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;4 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&#45;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M40.8847,-0.788883C48.6774,9.13921 59.4138,22.8175 67.2016,32.7393\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"27.8107\" cy=\"-86.5998\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"27.8107\" y=\"-82.8998\" font-family=\"Times,serif\" font-size=\"14.00\">5</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;5 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&#45;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M30.1395,-29.8261C29.6435,-41.918 28.9686,-58.3701 28.4731,-70.4512\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"-52.3363\" cy=\"19.5812\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"-52.3363\" y=\"23.2812\" font-family=\"Times,serif\" font-size=\"14.00\">6</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;6 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>0&#45;&#45;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M15.94,-7.69428C0.900289,-1.68613 -22.2271,7.55297 -37.3209,13.5827\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"82.9527\" cy=\"-31.1539\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"82.9527\" y=\"-27.4539\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>1&#45;&#45;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.746,-14.8854C80.7739,-1.77924 79.4147,16.5462 78.4483,29.5755\"/>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;5 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>1&#45;&#45;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M71.5272,-42.6423C62.0635,-52.1582 48.6812,-65.6143 39.2215,-75.1261\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"0.46552\" cy=\"1.25309\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"0.46552\" y=\"4.95309\" font-family=\"Times,serif\" font-size=\"14.00\">7</text>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;7 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>1&#45;&#45;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.8233,-25.21C52.9399,-19.3627 30.3491,-10.4874 15.499,-4.65317\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"-12.2509\" cy=\"147.473\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"-12.2509\" y=\"151.173\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"1.21884\" cy=\"75.7103\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"1.21884\" y=\"79.4103\" font-family=\"Times,serif\" font-size=\"14.00\">8</text>\n",
       "</g>\n",
       "<!-- 2&#45;&#45;8 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&#45;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-9.26157,131.546C-7.02939,119.654 -3.99235,103.474 -1.76219,91.5922\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"-107.261\" cy=\"-101.059\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"-107.261\" y=\"-97.3593\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"-48.666\" cy=\"-57.1294\" rx=\"16\" ry=\"16\"/>\n",
       "<text text-anchor=\"middle\" x=\"-48.666\" y=\"-53.4294\" font-family=\"Times,serif\" font-size=\"14.00\">9</text>\n",
       "</g>\n",
       "<!-- 3&#45;&#45;9 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>3&#45;&#45;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M-94.2569,-91.3099C-84.5467,-84.0299 -71.3353,-74.125 -61.6338,-66.8516\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&#45;8 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>4&#45;&#45;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.239,51.5147C48.9074,56.8009 29.5336,64.483 16.2115,69.7655\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&#45;9 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>5&#45;&#45;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12.7014,-80.7774C-0.706065,-75.6108 -20.1902,-68.1026 -33.5881,-62.9397\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&#45;8 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>6&#45;&#45;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M-41.2396,31.2112C-32.0483,40.8443 -19.0511,54.4662 -9.86361,64.0952\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&#45;9 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>6&#45;&#45;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M-51.5579,3.31284C-50.9309,-9.79316 -50.0541,-28.1184 -49.4307,-41.1475\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&#45;8 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>7&#45;&#45;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M0.628978,17.4092C0.755335,29.8982 0.929421,47.1047 1.0557,59.5857\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&#45;9 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>7&#45;&#45;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M-9.95402,-11.1283C-18.2918,-21.036 -29.9277,-34.8628 -38.2615,-44.7658\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Graph at 0x7fbfab43fe10>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_haplotype_network(h_aug, network_method='msn', show_node_labels=True, node_size_factor=0.2, debug=False, max_dist=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_haps_aug = h_aug.n_haplotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 3, 1, 1, 1, 3, 2, 2],\n",
       "       [2, 0, 3, 3, 1, 1, 3, 1, 2, 2],\n",
       "       [3, 3, 0, 4, 2, 4, 2, 2, 1, 3],\n",
       "       [3, 3, 4, 0, 4, 2, 2, 2, 3, 1],\n",
       "       [1, 1, 2, 4, 0, 2, 2, 2, 1, 3],\n",
       "       [1, 1, 4, 2, 2, 0, 2, 2, 3, 1],\n",
       "       [1, 3, 2, 2, 2, 2, 0, 2, 1, 1],\n",
       "       [3, 1, 2, 2, 2, 2, 2, 0, 1, 1],\n",
       "       [2, 2, 1, 3, 1, 3, 1, 1, 0, 2],\n",
       "       [2, 2, 3, 1, 3, 1, 1, 1, 2, 0]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_aug = allel.pairwise_distance(h_aug, metric='hamming')\n",
    "dist_aug *= h.n_variants\n",
    "dist_aug = scipy.spatial.distance.squareform(dist_aug).astype(int)\n",
    "dist_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges, alt_edges = minimum_spanning_network(dist_aug)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_edges = edges + alt_edges\n",
    "all_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 1 3\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 1 4\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 1 5\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 1 6\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 1 7\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 1 8\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 1 9\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 2 3\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 2 4\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 2 5\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 2 6\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 2 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 2 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 2 9\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 3 4\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 3 5\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 3 6\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 3 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 3 8\n",
      "n_pairs_linked 0\n",
      "0\n",
      "0 3 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 4 5\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 0 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 4 6\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 0 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 4 7\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 4 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 4 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 5 6\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 0 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 5 7\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 5 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 5 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 6 7\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 6 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 6 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "0 7 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 7 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "0 8 9\n",
      "n_pairs_linked 0\n",
      "0\n",
      "1 2 3\n",
      "n_pairs_linked 0\n",
      "0\n",
      "1 2 4\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 2 5\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 2 6\n",
      "n_pairs_linked 0\n",
      "0\n",
      "1 2 7\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 2 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 2 9\n",
      "n_pairs_linked 0\n",
      "0\n",
      "1 3 4\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 3 5\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 3 6\n",
      "n_pairs_linked 0\n",
      "0\n",
      "1 3 7\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 3 8\n",
      "n_pairs_linked 0\n",
      "0\n",
      "1 3 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 4 5\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 1 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "1 4 6\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 4 7\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 1 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "1 4 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "1 4 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 5 6\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 5 7\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 1 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "1 5 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 5 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 0 0 0]\n",
      "median vector already present\n",
      "0\n",
      "1 6 7\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 6 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 6 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "1 7 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 1 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "1 7 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 1 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "1 8 9\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 3 4\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 3 5\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 3 6\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 3 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 3 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "2 3 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "2 4 5\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 4 6\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 4 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 4 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "2 4 9\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 5 6\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 5 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 5 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "2 5 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "2 6 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "2 6 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "2 6 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "2 7 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "2 7 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "2 8 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "3 4 5\n",
      "n_pairs_linked 0\n",
      "0\n",
      "3 4 6\n",
      "n_pairs_linked 0\n",
      "0\n",
      "3 4 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "3 4 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "3 4 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "3 5 6\n",
      "n_pairs_linked 0\n",
      "0\n",
      "3 5 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "3 5 8\n",
      "n_pairs_linked 0\n",
      "0\n",
      "3 5 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "3 6 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "3 6 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "3 6 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "3 7 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "3 7 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "3 8 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "4 5 6\n",
      "n_pairs_linked 0\n",
      "0\n",
      "4 5 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "4 5 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "4 5 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "4 6 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "4 6 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "4 6 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "4 7 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "4 7 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "4 8 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "5 6 7\n",
      "n_pairs_linked 0\n",
      "0\n",
      "5 6 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "5 6 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "5 7 8\n",
      "n_pairs_linked 1\n",
      "0\n",
      "5 7 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "5 8 9\n",
      "n_pairs_linked 1\n",
      "0\n",
      "6 7 8\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "6 7 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 1 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "6 8 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [0 0 1 0 0]\n",
      "median vector already present\n",
      "0\n",
      "7 8 9\n",
      "n_pairs_linked 2\n",
      "computing median vector\n",
      "median vector [1 1 1 0 0]\n",
      "median vector already present\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i, j, k in itertools.combinations(range(n_haps_aug), 3): \n",
    "    n_medians_added = 0\n",
    "    print(i, j, k)\n",
    "    n_pairs_linked = 0\n",
    "    n_pairs_linked += all_edges[i, j] > 0\n",
    "    n_pairs_linked += all_edges[i, k] > 0\n",
    "    n_pairs_linked += all_edges[j, k] > 0\n",
    "    print('n_pairs_linked', n_pairs_linked)\n",
    "    if n_pairs_linked >= 2:\n",
    "        print('computing median vector')\n",
    "        uvw = h_aug[:, [i, j, k]]\n",
    "        uvw_ac = uvw.count_alleles(max_allele=1)\n",
    "        x = np.argmax(uvw_ac, axis=1)\n",
    "        print('median vector', x)\n",
    "        # TODO test if x already in haps_aug\n",
    "        if np.any(np.all(x[:, None] == np.asarray(h_aug), axis=0)):\n",
    "            print('median vector already present')\n",
    "        else:\n",
    "            print('adding median vector')\n",
    "            h_aug = allel.HaplotypeArray(np.column_stack([h_aug, x]))\n",
    "            n_medians_added += 1\n",
    "    print(n_medians_added)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
